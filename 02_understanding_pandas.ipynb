{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM7rQxQUU0zRJc1DcAFMBg3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YogenderSingh07/ibm-ml-learning/blob/main/02_understanding_pandas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2WY7b9qjdL4M"
      },
      "outputs": [],
      "source": [
        "!pip install pandas\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n"
      ],
      "metadata": {
        "id": "JiXvDLuQdr4-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##multiple cols -- data frame\n",
        "##single col -- series\n",
        "\n",
        "\n",
        "\n",
        "df = pd.read_csv('housing.csv')\n",
        "df.info() #gives the whole info about the data..for eg the data type\n",
        "## rows and cols--df.shape()\n",
        "df.head() ## first 5 rows\n",
        "df.tail() ## last 5 rows\n",
        "\n"
      ],
      "metadata": {
        "id": "-x2qtE3Ffp0f",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#COLS\n",
        "\n",
        "## to access data of more than one column(can be called dataframe),use square brackets twice\n",
        "df[['longitude','latitude']]\n",
        "# to know unique values of cols, df[colname].unique()\n",
        "df['longitude'].unique()\n",
        "\n",
        "#length of these unique vals can be found through the len() function\n",
        "len(df['longitude'].unique())\n",
        "#rename a column, pass old name as key & new name as a value(key-val pair)\n",
        "df.rename(columns={'longitude:height'},axis=1)\n",
        "\n",
        "#the data wont be updated permanently, to update it permanently,put inplace=true else variable reassignment like df = changes\n",
        "df.rename(columns={'longitude:height'},inplace=True)\n",
        "\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "BPaxSIcUfznR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from types import new_class\n",
        "#ROWS( indexing from 1-104)\n",
        "\n",
        "df.loc[102] ##loc will give the value of the row with index 102 -->will give the 102nd row\n",
        "df.iloc[102] ## iloc will give the row with 102th index..like python ---> will give 103rd row's data\n",
        "df.iloc[102:110]##slicing\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "PlqIuMcmm0EN",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#to acess first 4 rows and 3 cols\n",
        "df.iloc[0:4,0:3]   ##iloc doesnt need column name to access it, but in order to access from loc,we would need col name for it\n",
        "df.loc[0:4,['longitude','latitude','housing_median_age']]"
      ],
      "metadata": {
        "id": "6WMoP2oLtuJV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5dbc1939"
      },
      "source": [
        "### `drop()` method\n",
        "\n",
        "The `drop()` method is used to remove specified rows or columns from a DataFrame.\n",
        "\n",
        "*   To drop rows, specify the `index` or `labels` (row labels) and set `axis=0` (default).\n",
        "*   To drop columns, specify the `columns` or `labels` (column names) and set `axis=1`.\n",
        "*   `inplace=True` modifies the DataFrame in place, otherwise, it returns a new DataFrame.\n",
        "\n",
        "Let's drop a few rows and a column for demonstration. We will create a copy first to avoid altering the original `df` permanently."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "782cf2d2"
      },
      "source": [
        "df_copy = df.copy()\n",
        "\n",
        "# Drop rows with index 0 and 1\n",
        "df_dropped_rows = df_copy.drop(index=[0, 1])\n",
        "print(\"DataFrame after dropping rows 0 and 1:\")\n",
        "display(df_dropped_rows.head())\n",
        "\n",
        "# Drop the 'ocean_proximity' column\n",
        "df_dropped_col = df_copy.drop(columns=['ocean_proximity'])\n",
        "print(\"\\nDataFrame after dropping 'ocean_proximity' column:\")\n",
        "display(df_dropped_col.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c20c02b7"
      },
      "source": [
        "### `duplicated()` and `drop_duplicates()` methods\n",
        "\n",
        "*   The `duplicated()` method returns a boolean Series indicating whether each row is a duplicate of a previous row.\n",
        "*   The `drop_duplicates()` method removes duplicate rows from the DataFrame.\n",
        "\n",
        "Let's add some duplicate rows to our DataFrame copy to demonstrate."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b946f655"
      },
      "source": [
        "df_with_duplicates = df.copy()\n",
        "# Add some duplicate rows for demonstration\n",
        "df_with_duplicates = pd.concat([df_with_duplicates, df_with_duplicates.iloc[:5]], ignore_index=True)\n",
        "\n",
        "print(\"DataFrame with added duplicate rows (first 10 rows):\")\n",
        "display(df_with_duplicates.head(10))\n",
        "\n",
        "# Identify duplicate rows\n",
        "duplicate_rows = df_with_duplicates.duplicated()\n",
        "print(\"\\nBoolean Series indicating duplicate rows:\")\n",
        "display(duplicate_rows.head(10))\n",
        "\n",
        "# Drop duplicate rows\n",
        "df_no_duplicates = df_with_duplicates.drop_duplicates()\n",
        "print(\"\\nDataFrame after dropping duplicate rows (first 10 rows):\")\n",
        "display(df_no_duplicates.head(10))\n",
        "print(f\"Original rows: {len(df_with_duplicates)}, Rows after dropping duplicates: {len(df_no_duplicates)}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9f988ce"
      },
      "source": [
        "### `reset_index()` method\n",
        "\n",
        "The `reset_index()` method resets the index of the DataFrame. The old index is added as a new column, and a new default integer index is used.\n",
        "\n",
        "*   `drop=True` prevents the old index from being added as a new column.\n",
        "*   `inplace=True` modifies the DataFrame in place."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aaf5d1e8"
      },
      "source": [
        "df_reset_example = df.iloc[5:10].copy()\n",
        "print(\"Original DataFrame slice:\")\n",
        "display(df_reset_example)\n",
        "\n",
        "# Reset index, keeping the old index as a column\n",
        "df_reset_with_col = df_reset_example.reset_index()\n",
        "print(\"\\nDataFrame after `reset_index()` (old index becomes a column):\")\n",
        "display(df_reset_with_col)\n",
        "\n",
        "# Reset index, dropping the old index\n",
        "df_reset_dropped = df_reset_example.reset_index(drop=True)\n",
        "print(\"\\nDataFrame after `reset_index(drop=True)` (old index is dropped):\")\n",
        "display(df_reset_dropped)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#min max mean\n",
        "print(df['total_rooms'].min())\n",
        "print(df['total_rooms'].max())\n",
        "print(df['total_rooms'].mean())"
      ],
      "metadata": {
        "id": "TqY83JaOwRGT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#SORTING COLS\n",
        "df.sort_values(['housing_median_age']) #ascending is true by default\n",
        "df.sort_values(['housing_median_age'],ascending = False) #ascending is false for descending order\n",
        "df.sort_values(['housing_median_age','total_rooms'],ascending=False)#sorting multiple cols"
      ],
      "metadata": {
        "collapsed": true,
        "id": "crcR9HtdBATR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#creating a Dataframe --dictionary like key-val pair\n",
        "users = pd.DataFrame({'user_id':[1,2,3,4],'name':[\"rishit\",\"yogender\",\"aman\",\"VANSH\"]})\n",
        "messages = pd.DataFrame({'OS':[\"IOS\",\"ANDROID\",\"ANDROID\",\"IOS\"],'Message':[\"hmm\",\"ok\",\"nice\",\"thankyou\"],'user_id':[1,2,3,4]})\n"
      ],
      "metadata": {
        "id": "eHborzQ5CaOD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Concatenate , axis =0 is vertical concatination - the stack dataframe one on top of other, axis =1 To place DataFrames side by side, use axis=1. This is useful when the DataFrames have the same rows (matching indices) but different columns (representing different features or attributes).\n",
        "pd.concat([users,messages],axis=1)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "IrXgYaZfCPIY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#merge\n",
        "users.merge(messages,on='user_id')\n",
        "\n",
        "messages_by_os = messages.groupby('OS')['Message'].count()\n",
        "print(messages_by_os)\n",
        "\n",
        "\n",
        "messages_by_os = (\n",
        "    messages.groupby('OS')\n",
        "            .agg(Message_Count=('Message', 'count'))\n",
        ")\n",
        "print(messages_by_os)\n",
        "\n"
      ],
      "metadata": {
        "id": "TRJzeuv9Gnt1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}